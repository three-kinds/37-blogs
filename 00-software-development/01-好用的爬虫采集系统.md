# 好用的爬虫采集系统

## 0. 背景

* 我有过好几年的爬虫开发经历，接口爬虫、自动化爬虫都做过一些，深刻了解采集系统的重要性
* 我写过几年的后端应用，认为后端有很多好用的经验与轮子
* 我写过几版采集系统，期望通过文本记录自己追求好用的采集系统的心路历程

## 1. 采集系统是怎样发展而来的

1. 爬虫的开发与执行有较相似的流程，如获取数据、提取数据、保存数据；在这一步，有很多优秀的开源框架，如Scrapy，让我们专注于爬虫特有逻辑开发
2. 需要更高效采集时，通常会通过集群去增大爬虫规模；在这一步，有Scrapy-Redis帮助Scrapy爬虫集群化
3. 为了保证稳定的数据供给，通常需要任务管理、运行监控、告警等运维能力；在这一步，有ScrapydWeb帮助我们管理Scrapy集群
4. 它们共同组成了采集系统：将共有的逻辑从具体爬虫提取到通用的组件、框架、系统中

## 2. 我心目中好用的采集系统

1. 开发舒适：专注于开发爬虫站点流程与难点；各种类型的爬虫都支持、各种组件都可选、甚至不挑编程语言
2. 便于测试：应当支持并易于单元测试、整体流程测试（像普通的后端应用那样）
3. 集群运行：应当在不改代码的情况下就可以切换运行模式，单机运行、集群运行（像普通的后端应用那样）
4. 任务管理：任务调度与管理由采集系统或外部系统维护，爬虫不应当也不知道自己目前在运行的是个实时响应任务还是个批量采集任务
5. 通用工具：通用工具如告警、代理池应当服务化、一方面让爬虫专注于爬虫，另一方面便于这些通用服务的规模缩放
6. 运维：普通的监控、日志、规模缩放应当要复用现成的工具，如Prometheus、ELK、Kubernetes等

### 2.1 开发舒适

1. 语言自由选择
2. 组件自由选择
3. 各种爬虫类型都支持
4. 仍能专注爬虫开发

### 2.2 便于测试



### 2.3 运行模式的切换


### 2.4 任务管理


### 2.5 通用工具


### 2.6 运维

