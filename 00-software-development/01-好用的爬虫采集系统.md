# 好用的爬虫采集系统

## 0. 背景

* 我有过好几年的爬虫开发经历，接口爬虫、自动化爬虫都做过一些，深刻了解采集系统的重要性
* 我写过几年的后端应用，认为后端有很多好用的经验与轮子
* 我写过几版采集系统，期望通过文本记录自己追求好用的采集系统的心路历程

## 1. 采集系统是怎样发展而来的

1. 爬虫的开发与执行有较相似的流程，如获取数据、提取数据、保存数据；在这一步，有很多优秀的开源框架，如Scrapy，让我们专注于爬虫特有逻辑开发
2. 需要更高效采集时，通常会通过集群去增大爬虫规模；在这一步，有Scrapy-Redis帮助Scrapy爬虫集群化
3. 为了保证稳定的数据供给，通常需要任务管理、运行监控、告警等运维能力；在这一步，有ScrapydWeb帮助我们管理Scrapy集群
4. 它们共同组成了采集系统：将共有的逻辑从具体爬虫提取到通用的组件、框架、系统中

## 2. 我心目中好用的采集系统

1. 开发舒适：专注于开发爬虫站点流程与难点；各种类型的爬虫都支持、各种组件都可选、甚至不挑编程语言
2. 便于测试：应当支持并易于单元测试、整体流程测试（像普通的后端应用那样）
3. 集群运行：应当在不改代码的情况下就可以切换运行模式，单机运行、集群运行（像普通的后端应用那样）
4. 任务管理：任务调度与管理由采集系统或外部系统维护，爬虫不应当也不知道自己目前在运行的是个实时响应任务还是个批量采集任务
5. 通用工具：通用工具如告警、代理应当服务化、让爬虫专注于爬虫，也便于这些通用服务的规模缩放
6. 运维：普通的监控、日志、规模缩放应当要复用现成的工具，如Prometheus、ELK、Kubernetes等

### 2.1 开发舒适

1. 专注爬虫开发：专注于站点流程、加解密、逆向等特有逻辑；数据下载、抽取、存储等通用逻辑都用现成的组件。这需要一个好用且没有多少约束的爬虫开发框架
2. 语言自由选择：每个语言都有这样的一个框架
3. 组件自由选择：框架不应当有过多的限制和绑架，可结合其它好用的轮子，框架内的组件都是可替换的
4. 各种爬虫类型都支持：支持接口采集、桌面程序自动化、Web自动化、App自动化等类型；本质上是因为组件可自由选择，所以爬虫类型支持的范围才更广

### 2.2 便于测试

1. 单元测试与覆盖测试是很重要的，一定要支持；解析流程写不写单元测试区别是很大的
2. 整体流程的单机测试便于本地开发

### 2.3 运行模式的切换

1. 应当在不改代码的情况下就可以切换运行模式，单机模式、集群节点模式
2. 后端通常通过不同的配置来改变不同环境依赖的组件与具体配置，这也完全可以借鉴过来

### 2.4 任务管理

1. 无论是业务相关的任务还是集群相关的任务，都不应当耦合到爬虫中、应当由外部系统、采集系统来维护
2. 即使是性能要求非常高的实时响应任务、或量非常大的批量采集任务，它们也都是业务任务
3. 爬虫只专注于单元采集任务的处理，只处理单元采集流程，爬虫不应当也不知道自己目前在运行的是什么业务、什么优先级的任务

### 2.5 通用工具

1. 像告警、代理、验证码识别等通用工具，应当服务化，通过不变的接口去使用，一方面可以让爬虫更专注，另一方面当工具服务核心更换时，爬虫也无需改动
2. 当对通用服务的需求变化时，也可以通过通用的服务扩展方法来缩放服务

### 2.6 运维

1. 运维工具的选择，要优先考虑是否可以接入现有的运维系统，比如监控使用Prometheus、日志使用ELK、集群管理使用Kubernetes，好用且接入简单
2. 爬虫节点规模的缩放、通用服务的规模缩放等运维方法，都应当考虑使用现有的工具，而不是自己造轮子
3. 只有像站点改版监控这样关联面可能较多的需求，才考虑自己实现监控服务：通过结合采集系统的任务管理与确定的目标数据结果来实现站点改版的监控
